# This RBS is unofficial.
# The above declaration is a requirement for publishing the RBS for sidekiq-pro and sidekiq-ent, so please do not remove it.

module Sidekiq::Component
  def leader?: () -> untyped
end
module Sidekiq
  module Enterprise
    # The leader runs this code nightly to scan the current Sidekiq
    # Enterprise cluster and upload census data to contribsys.  This collection
    # is allowed under Section 11 of the COMM-LICENSE.
    #
    # It uploads aggregate metrics and license info, never any source code or user data.
    #
    class Census
      @config: untyped

      @helpers: untyped

      @creds: untyped

      @rver: untyped

      @sver: untyped

      @ever: untyped

      @thread: untyped

      include Sidekiq::Component

      def initialize: (untyped config, ?untyped settings, ?::String hostname, ?untyped helpers) -> void

      def start: () -> (nil | untyped)

      def user: () -> untyped

      def pwd: () -> untyped

      def perform: () -> true

      # Leaders send their daily census report during the hour of 3AM Pacific
      def pause: (?::Integer hour) -> untyped

      def valid?: () -> bool

      def env: () -> untyped

      def minute: () -> untyped

      def scale_metrics: () -> ::Array[untyped]

      def network_call: (untyped uri) -> untyped

      def fallback: (untyped p) -> nil

      def urlsafe_encode64: (untyped bin) -> untyped

      def parameterize: () -> { v: 1, tag: untyped, rver: untyped, sver: untyped, ever: untyped, threads: untyped, processes: untyped, jobs: untyped, user: untyped }

      def fetch_creds: (untyped settings, untyped hostname) -> (untyped | ::String | nil)
    end
  end
end
module Sidekiq
  # keep these names short to minimize overhead
  Enc: untyped

  module Enterprise
    # This class can auto-{en,de}crypt a secret argument for
    # sensitive payloads.  You enable the feature by
    # initializing it:
    #
    #   Sidekiq::Enterprise::Crypto.enable(active_version: 1) do |version|
    #     <return key>
    #   end
    #
    # where the block must return the bytes of the symmetric key to use
    # for encryption and decryption of the given version.  With key rotation,
    # you bump the active_version and supply the new key for that new version.
    #
    # You can create a random key using OpenSSL and `irb`:
    #
    #   require 'openssl'
    #   File.open("/tmp/my1.key", "w") { |file| file.write(OpenSSL::Cipher.new("aes-256-cbc").random_key) }
    #
    # and now tell Sidekiq about it:
    #
    #   Sidekiq::Enterprise::Crypto.enable(active_version: 1) do |version|
    #     File.read("/tmp/my#{version}.key")
    #   end
    #
    # If using Heroku, you can load the secret key into an ENV var and access that instead.
    #
    # Once you've set up the crypto subsystem, you can activate encryption for a
    # given Job's arguments like so:
    #
    #     class MySecretJob
    #       include Sidekiq::Job
    #       sidekiq_options encrypt: true
    #
    # NOTES
    # ----------
    #
    # * Encryption adds about 100 bytes to the size of arguments.  My MBP can perform about 70,000 enc/dec
    #   round trips per second.
    # * **ONLY** the last argument is encrypted.  Any error message and backtrace will still be plaintext within a job.
    # * The unique jobs feature will not work on encrypted jobs, since all encrypted arguments are unique.
    #
    module Crypto
      def self.enable: (?::Hash[untyped, untyped] opts) { (?) -> untyped } -> untyped

      class Default
        @version: untyped

        @block: untyped

        @cipher: untyped

        KEYS: ::Hash[untyped, untyped]

        def initialize: (?::Hash[untyped, untyped] opts) { (?) -> untyped } -> void

        def key_for: (untyped version) -> untyped

        # Encrypts `thing`, returns a blob of binary data.
        def encrypt: (untyped thing) -> untyped

        # Decrypts the blob of data, returning `thing`
        def decrypt: (untyped blob) -> untyped
      end

      SCHEMES: ::Hash[untyped, untyped]

      NON_BASE64: ::Regexp

      class Client
        include Sidekiq::ClientMiddleware

        def call: (untyped job_klass, untyped job, untyped queue, untyped redis_pool) { () -> untyped } -> untyped

        def encrypt: (untyped thing, untyped scheme) -> untyped
      end

      class Server
        include Sidekiq::ServerMiddleware

        def call: (untyped inst, untyped job, untyped queue) { () -> untyped } -> untyped

        def decrypt: (untyped str, untyped scheme) -> untyped
      end
    end
  end
end

# Implements a simple HTTP-server by using John W. Small's (jsmall@laser.net)
# ruby-generic-server: GServer.
#
# FIXME: The ::GServer constant has no sig.
class Sidekiq::HttpServer # < ::GServer
  @handler: untyped

  #
  # +handle_obj+ specifies the object, that receives calls from +request_handler+
  # and +ip_auth_handler+
  def initialize: (untyped handle_obj, ?::Integer port, ?untyped host, ?::Integer maxConnections, ?untyped stdlog, ?bool audit, ?bool debug) -> void
end
module Sidekiq
  module Limiter
    self.@redis: untyped

    LEGAL_NAME: ::Regexp

    DEFAULT_TTL: untyped

    DEFAULT_RESCHEDULE: 20

    DEFAULT_OPTIONS: { lock_timeout: 30, wait_timeout: 5, policy: :raise, ttl: untyped, reschedule: untyped }

    class OverLimit < ::RuntimeError
      @limiter: untyped

      attr_accessor limiter: untyped

      def initialize: (untyped limiter) -> void

      def to_s: () -> untyped
    end

    # Globally configure the Limiter subsystem:
    #
    # Sidekiq::Limiter.configure do |config|
    #   config.redis = { url: 'redis://localhost/0' }
    #   config.errors << Foo::Bar
    #   config.backoff = ->(limiter, job, ex) do
    #     10
    #   end
    # end
    def self.configure: () { (untyped) -> untyped } -> untyped

    def self.redis=: (untyped pool) -> untyped

    def self.redis: () ?{ (untyped) -> untyped } -> untyped

    def self.redis_pool: () -> untyped

    def self.logger: () -> untyped

    DEFAULT_BACKOFF: untyped

    attr_accessor self.errors: untyped

    attr_accessor self.backoff: untyped

    #
    # Register a concurrent rate limiter within Redis.
    #
    # Limit to 50 concurrent ERP operations:
    #
    #     Sidekiq::Limiter.concurrent(:erp, 50, wait_timeout: 10)
    #
    # Options:
    #   :ttl - time for the data to live in Redis, default 90 days
    #   :lock_timeout - seconds before a concurrent lock is automatically released, necessary if a
    #     process crashes while holding a lock, default 30.  **Your concurrent operations
    #     must take less than this amount of time!**
    #   :wait_timeout - seconds to wait for the rate limit or raises a
    #     Sidekiq::Limiter::OverLimit, 0 means never wait, default 5
    #   :policy - what should the API do if rate limit cannot be met, legal values: [:raise, :skip],
    #     :raise will raise Sidekiq::Limiter::OverLimit, :skip will return without executing the block,
    #     defaults to :raise
    #   :backoff - a Proc(limiter, job, ex) which calculates an integer number of seconds to pause before retrying in case of OverLimit
    #
    def self.concurrent: (String name, Integer count, ?Hash[Symbol, untyped] options) -> Sidekiq::Limiter::Concurrent

    #
    # Register a bucket-based rate limiter within Redis.  Buckets can be
    # per :second, :minute, :hour or :day.
    #
    # Limit Stripe operations to 10 per second:
    #
    #     Sidekiq::Limiter.bucket(:stripe, 10, :second)
    #
    # Bucket means that you can perform 10 operations at 12:44:03.999 and
    # then another 10 operations at 12:44:04.000, because each interval is
    # considered a bucket.
    #
    # Options:
    #   :ttl - time for the data to live in Redis, default 90 days
    #   :wait_timeout - seconds to wait for the rate limit or raises a
    #     Sidekiq::Limiter::OverLimit, 0 means never wait, default 5
    #   :policy - what should the API do if rate limit cannot be met, legal values: [:raise, :skip],
    #     :raise will raise Sidekiq::Limiter::OverLimit, :skip will return without executing the block,
    #     defaults to :raise
    #   :backoff - a Proc(limiter, job, ex) which calculates an integer number of seconds to pause before retrying in case of OverLimit
    #
    def self.bucket: (untyped name, untyped count, untyped interval, ?::Hash[untyped, untyped] options) -> untyped

    #
    # Register a "leaky bucket"-based rate limiter within Redis.
    # You define it to allow X operations per Y seconds.
    #
    # The leaky bucket allows the caller to perform X operations immediately
    # but then the bucket slowly leaks, emptying over Y seconds.
    #
    # Limit Shopify operations to 20 every 5 seconds:
    #
    #     Sidekiq::Limiter.leaky(:shopify, 20, 5)
    #
    # One important note:
    #
    #     Sidekiq::Limiter.leaky(:shopify, 4, :second)
    #     Sidekiq::Limiter.leaky(:shopify, 240, :minute)
    #
    # These are the same ratios (240 / 60) vs (20 / 5) vs (4 / 1) with one important
    # caveat: the numerator is the burst allowance. The user can only
    # burst 4 operations before throttling, whereas the previous allows
    # 20 operations before throttling. The last one allows 240 simultaneous
    # operations before throttling, it's up to you to determine how much burst leeway
    # you want to give to your users. Once full, they all drain at the same rate.
    #
    # Options:
    #   :ttl - time for the data to live in Redis, default 24 hours
    #   :wait_timeout - seconds to wait for the rate limit or raises a
    #     Sidekiq::Limiter::OverLimit, 0 means never wait, default 5
    #   :policy - what should the API do if rate limit cannot be met, legal values: [:raise, :skip],
    #     :raise will raise Sidekiq::Limiter::OverLimit, :skip will return without executing the block,
    #     defaults to :raise
    #   :backoff - a Proc(limiter, job, ex) which calculates an integer number of seconds to pause before retrying in case of OverLimit
    #
    def self.leaky: (untyped name, untyped count, untyped interval, ?::Hash[untyped, untyped] options) -> untyped

    #
    # Register a points-based leaky bucket rate limiter within Redis.
    # This type of limiter is frequently used with GraphQL APIs from
    # companies like Shopify or GitHub. For example: you get 10,000 points per
    # minute. An arbitrary GraphQL query might use 300 or 1000 points.
    # You need to provide an estimate for the number of points which will be consumed by
    # your operation and the rate limiter will ensure your call has at least that many points
    # left.
    #
    # For Shopify:
    #
    #   > Each combination of app and store is given a bucket of 1000 cost points, with a leak rate
    #   > of 50 cost points per second. This means that the total cost of your queries cannot exceed
    #   > 1,000 points at any given time, and that room is created in the app’s bucket at a rate of
    #   > 50 points per second.
    #
    #     Sidekiq::Limiter.points(:shopify, 1000, 20)
    #
    # Options:
    #   :ttl - time for the data to live in Redis, default 24 hours
    #   :wait_timeout - seconds to wait for the rate limit or raises a
    #     Sidekiq::Limiter::OverLimit, 0 means never wait, default 5
    #   :policy - what should the API do if rate limit cannot be met, legal values: [:raise, :skip],
    #     :raise will raise Sidekiq::Limiter::OverLimit, :skip will return without executing the block,
    #     defaults to :raise
    #   :backoff - a Proc(limiter, job, ex) which calculates an integer number of seconds to pause before retrying in case of OverLimit
    #
    def self.points: (untyped name, untyped count, untyped interval, ?::Hash[untyped, untyped] options) -> untyped

    #
    # Register a sliding-window-based rate limiter within Redis.  The window can be
    # per :second, :minute, :hour or :day.
    #
    # Limit banking operations to 10 per second:
    #
    #     Sidekiq::Limiter.window(:banking, 10, :second)
    #
    # Options:
    #   :ttl - time for the data to live in Redis, default 90 days
    #   :wait_timeout - seconds to wait for the rate limit or raises a
    #     Sidekiq::Limiter::OverLimit, 0 means never wait, default 5
    #   :policy - what should the API do if rate limit cannot be met, legal values: [:raise, :skip],
    #     :raise will raise Sidekiq::Limiter::OverLimit, :skip will return without executing the block,
    #     defaults to :raise
    #   :backoff - a Proc(limiter, job, ex) which calculates an integer number of seconds to pause before retrying in case of OverLimit
    #
    def self.window: (untyped name, untyped count, untyped interval, ?::Hash[untyped, untyped] options) -> untyped

    # Provide a simple unlimited rate limiter for test environments and bypassing
    # an existing rate limit in certain cases.  Allow any args so it can
    # dynamically swap with a real limiter.
    def self.unlimited: (*untyped args) -> untyped
  end
end
module Sidekiq::Enterprise
  class Liveness < Sidekiq::HttpServer
    @config: untyped

    @key: untyped

    include Sidekiq::Component

    def initialize: (untyped iface, ?untyped cfg) ?{ (untyped) -> untyped } -> void

    def ip_auth_handler: (*untyped) -> true

    def request_handler: (untyped req, untyped res) -> untyped
  end
end

class Sidekiq::Config
  #
  # Start a simple HTTP server which returns 200/OK and JSON data if the current
  # process is alive, used for Kubernetes health checks and similar.
  #
  # Examples:
  #   health_check(":7433") # binds to all interfaces, 0.0.0.0
  #   health_check("127.0.0.1:7433")
  #   health_check("[::1]:7433")
  #   health_check(7433) # binds to 127.0.0.1
  def health_check: (?::Integer iface) { (?) -> untyped } -> untyped
end
class Sidekiq::Config
  def retain_history: (?::Integer interval) { (?) -> untyped } -> untyped
end

module Sidekiq
  module Enterprise
    class History
      @config: untyped

      @done: untyped

      @interval: untyped

      @thread: untyped

      include Sidekiq::Component

      attr_accessor interval: untyped

      attr_accessor custom: untyped

      def initialize: (untyped config) -> void

      def start: () -> untyped

      def stop: () -> untyped

      def run: () -> untyped

      def capture: () -> untyped

      def capture_default: (untyped stats) -> untyped
    end
  end
end
class Sidekiq::Config
  #
  # A Loop generates jobs on some schedule, e.g. process new orders every 15 minutes.
  # Loops are registered on startup.
  #
  # Here's how to register a loop:
  #
  #   Sidekiq.configure_server do |config|
  #     config.periodic do |mgr|
  #       mgr.register "*/4 * * * * *", "ProcessOrders", retry: 3
  #     end
  #   end
  #
  def periodic: () ?{ (untyped) -> untyped } -> (untyped | nil)
end

module Sidekiq
  module Periodic
    class LoopSet
      @lids: untyped

      include Enumerable[untyped]

      def initialize: () -> void

      def size: () -> untyped

      def each: () { (untyped) -> untyped } -> untyped
    end

    class Loop
      @lid: untyped

      @klass: untyped

      @schedule: untyped

      @tz_name: untyped

      @options: untyped

      @source: untyped

      attr_reader klass: untyped

      attr_reader schedule: untyped

      attr_reader lid: untyped

      attr_reader tz_name: untyped

      attr_reader options: untyped

      def initialize: (untyped lid) -> void

      def next_run: () -> untyped

      def time_source: () -> untyped

      # returns [jid, epoch integer] pairs for each execution
      def history: () -> untyped
    end
  end
end
module Sidekiq
  module Enterprise
    module Scripting
      LUA: ::Hash[untyped, untyped]

      SHAS: ::Hash[untyped, untyped]

      def self.bootstrap: (untyped config) -> untyped

      def self.call: (untyped name, untyped keys, untyped args, untyped config) -> untyped
    end
  end
end
module Sidekiq
  #
  # The Senate abstraction allows a cluster of Sidekiq processes,
  # all talking through a shared Redis instance, to elect and maintain
  # a leader.
  #
  # Leaders renew leadership every 15 seconds.  If they have not renewed within
  # 60 seconds, any other connected processes can assume leadership.
  #
  # When shutting down, the Leader "steps down" so that a new process can immediately
  # assume leadership upon startup.  Note that a "quiet" leader process still runs
  # its leadership tasks.  It does not step down until TERM - this is to ensure cron
  # jobs are still fired even during a long quiet period.
  #
  class Senate
    @config: untyped

    @key: untyped

    @leader_until: untyped

    @keys: untyped

    @args: untyped

    @done: untyped

    @thread: untyped

    @listener: untyped

    @sleeper: untyped

    include Sidekiq::Component

    TTL: 60

    def initialize: (untyped config) -> void

    def terminate: () -> untyped

    def start: () -> untyped

    def stop!: () -> (nil | untyped)

    def leader?: () -> untyped

    def stage_coup!: () -> (false | untyped)

    def cycle: () -> untyped

    def election: () -> untyped
  end
end
module Sidekiq
  module Enterprise
    class Systemd
      @active: untyped

      def initialize: () -> void

      def watchdog!: () -> (untyped | nil)

      def stopping: () -> (untyped | nil)

      def ready: () -> (untyped | nil)
    end

    # Create a set of child Sidekiq processes underneath a parent
    # process.  We use Bundler.require to pull in the entire set of
    # gems used by the application so we get benefit of CoW memory sharing.
    #
    # Note that we fork the children before loading the app so we won't get
    # as much memory saving as we could otherwise. App preload is fraught
    # with peril; gem preload is safer.
    class Swarm
      @env: untyped

      @argv: untyped

      @signal: untyped

      @io: untyped

      @ppid: untyped

      @count: untyped

      @trackmem: untyped

      @stopping: untyped

      @max_kb: untyped

      @last_spawn: untyped

      @systemd: untyped

      @preload: untyped

      @cmd: untyped

      BOOT_TIMEOUT: 60

      attr_accessor count: untyped

      attr_accessor children: untyped

      attr_accessor io: untyped

      attr_accessor ppid: untyped

      def initialize: (?untyped env, ?untyped argv, ?untyped signal) -> void

      def start: () -> untyped

      def prepare_for_fork: () -> untyped

      def parse: () -> untyped

      def start_and_monitor: () -> untyped

      def monitor: (?bool wait) -> (nil | untyped)

      def check_children: (untyped last) -> untyped

      def ps_cmd: () -> untyped
    end
  end
end
module Sidekiq
  module Enterprise
    #
    # The Unique middleware adds a check before the push of a Sidekiq
    # job to Redis to see if the same job is already thought to be within Redis.
    #
    # This sets a tag in Redis which expires in N seconds. The same job cannot
    # be enqueued while this tag exists.
    #
    # When `perform` returns successfully we clear the tag so another identical
    # job can be enqueued at that point.  A raised error does **not** clear out
    # the tag so the same job cannot be pushed while the errored job is pending retry.
    #
    # If you are scheduling a unique job to run in the future, the uniqueness
    # will last until after the job is scheduled to run:
    #
    #     class MyUniqueJob
    #       include Sidekiq::Job
    #       sidekiq_options unique_for: 5 minutes
    #     end
    #     MyUniqueJob.perform_in(1.hour, 1, 2, 3)
    #
    # Other duplicate jobs will be ignored for 65 minutes or until the job runs
    # successfully (in 60 minutes).
    #
    # You can "force push" a job to Redis by overriding `unique_for` to false:
    #
    #     MyUniqueJob.set(unique_for: false).perform_async(1,2,3)
    #
    # There are several caveats with this feature and ways in which it can fail.
    # Do not depend on it for guaranteed uniqueness but rather as a way to prune
    # redundant jobs.  Your jobs should still be idempotent.
    #
    # Caveats:
    #
    # 1. Only works with simple parameters, no symbols, objects, etc, as the parameters
    #    must go thru the JSON serialization round trip without modification.
    # 2. If the job raises an error and does not retry, the tag will remain in Redis
    #    until it expires.  If you don't want jobs to retry, you should also set their
    #    uniqueness period very short.
    #
    # Usage:
    #
    # In your initializer:
    #
    #     Sidekiq::Enterprise.unique! unless Rails.env.test?
    #
    # In your job:
    #
    #     sidekiq_options unique_for: 20.minutes
    #
    module Unique
      UNIQUE_KEY: "unique_for"

      UNIQUE_UNTIL: "unique_until"

      LOCKED_KEY: "unlocks_at"

      TOKEN_KEY: "unique_token"

      # Check to see if the unique lock is currently present
      # for the given (queue, klass, args) tuple.  Keep in mind that
      # the args must be *exactly* what would be deserialized
      # from JSON so no symbols, objects or non-JSON datatypes.
      #
      # Note this method IS RACY.  It can return false and then another
      # thread take the lock microseconds later - treat it as advisory only.
      #
      # Returns truthy if the unique lock is present.
      #
      def self.locked?: (?untyped? queue, untyped klass, untyped args) -> untyped

      # Special case AJ's wrapper class so unique locks can work
      # with AJ's special argument handling.
      def self.default_context_for: (untyped _, untyped job) -> ::Array[untyped]

      # If you wish to control the elements which Sidekiq Enterprise
      # uses to calculate the lock, you can implement `sidekiq_unique_context`
      # as a class method on your job. This method should return the Array of
      # elements. See above for the default implementation which handles both
      # Sidekiq::Job and ActiveJob::Base.
      def self.context_for: (untyped _, untyped job) -> untyped

      class Client
        include Sidekiq::ClientMiddleware

        def call: (untyped inst, untyped job, untyped queue, untyped redis_pool) { () -> untyped } -> (untyped | false)
      end

      def self.unlock: (untyped job, ?untyped cfg) -> (nil | untyped)

      class Server
        include Sidekiq::ServerMiddleware

        def call: (untyped inst, untyped job, untyped queue) { () -> untyped } -> untyped
      end
    end

    def self.unique!: () -> untyped
  end
end
module Sidekiq
  module Enterprise
    VERSION: "7.3.4"

    MAJOR: 7

    def self.gem_version: () -> untyped
  end
end
module Sidekiq::Enterprise
  module Web
    ROOT: untyped

    module Helpers
      def product_version: () -> ::String
    end

    def self.registered: (untyped app) -> untyped

    class Authorization
      @app: untyped

      @authorize: untyped

      def initialize: (untyped app) { (?) -> untyped } -> void

      def call: (untyped env) -> untyped
    end
  end
end

class Sidekiq::Web
  def self.authorize: () { (?) -> untyped } -> untyped
end
module Sidekiq
  module Limiter
    class Base
      @name: untyped

      @options: untyped

      @wait_for: untyped

      attr_reader name: untyped

      attr_reader options: untyped

      attr_reader wait_for: untyped

      def initialize: (untyped name, untyped options) -> void

      def key: () -> untyped

      def status: () -> untyped

      def backoff: () -> untyped

      def ttl: () -> untyped

      def policy: () -> untyped

      def reschedule: () -> untyped

      def to_s: () -> untyped

      def pause: (untyped length) -> untyped
    end
  end
end
module Sidekiq
  module Limiter
    class Bucket < Base
      @size: untyped

      @interval: untyped

      # this doesn't need to be thread-safe as this operation
      # is idempotent so the race condition is fine.
      @done: untyped

      @key: untyped

      INTERVALS: untyped

      attr_reader interval: untyped

      attr_reader size: untyped

      alias count size

      # Create a rate limiter of +size+ per +interval+, e.g. 5 per second.
      #
      # Resets at the start of each interval so it's possible to perform
      # more than +size+ operations in a given interval, e.g. you can perform 5
      # operations at 12:03:58.999 and then another 5 operations at 12:03:59.001
      # since the interval resets at 12:03:59.000.
      #
      # Name should be a URL-safe descriptor, i.e. "user_12345", not "Bob's Rate".
      #
      def initialize: (untyped name, untyped size, untyped interval, untyped options) -> void

      def establish: () -> untyped

      def key: () -> untyped

      #
      # Yield if the current interval has not gone over limit.
      # :used is the number of points used by this call, defaulting to 1.
      #
      # If this is a :second-based limiter, will +sleep+ up to
      # +wait_timeout+ seconds until it can fit within limit or
      # raise Sidekiq::Limiter::OverLimit.
      def within_limit: (?used: ::Integer) { () -> void } -> void
    end
  end
end
module Sidekiq
  module Limiter
    def self.within_all_limits: (*untyped limiters) { () -> untyped } -> untyped
  end
end
module Sidekiq
  module Limiter
    #
    # A concurrent limiter allows a block to execute iff it can
    # obtain a token. It tracks the following metrics:
    #
    # - Number of times a thread got a token immediately
    # - Number of times a thread had to wait for a token
    # - Number of times a thread could not get a token.
    # - Number of times a thread held a token for more than the locktime
    # - Total wait time to get a token
    # - Total held time for a token
    #
    # +name+ should be a URL-safe descriptor, i.e. "user_12345", not "Bob's Rate".
    # +policy+ can be :raise (default) to raise OverLimit if a token cannot be obtained within +wait_timeout+,
    #   or :ignore if the block should be skipped if the rate limit can't be fulfilled.
    #
    class Concurrent < Base
      @free: untyped

      @pend: untyped

      @used: untyped

      @size: untyped

      # this doesn't need to be thread-safe as this operation
      # is idempotent so the race condition is fine.
      @done: untyped

      @lock_for: untyped

      @key: untyped

      attr_reader size: untyped

      def initialize: (untyped name, untyped size, untyped options) -> void

      def establish: () -> untyped

      def lock_for: () -> untyped

      def key: () -> untyped

      def within_limit: () { () -> untyped } -> (nil | untyped)
    end
  end
end
module Sidekiq
  module Limiter
    #
    # Implements a leaky bucket rate limiter.
    #
    # Each limiter is bucket which holds X drops. The bucket
    # drains in Y seconds, a drop every (Y/X) seconds. Callers
    # may fill up the bucket as fast as they want but once full,
    # future calls will be throttled based on the drain rate.
    class LeakyBucket < Base
      @size: untyped

      @interval: untyped

      @key: untyped

      attr_reader size: untyped

      attr_reader interval: untyped

      def initialize: (untyped name, untyped size, untyped interval, untyped options) -> void

      def key: () -> untyped

      def within_limit: () { () -> untyped } -> (untyped | nil)

      class Result
        @limiter: untyped

        @next_drip: untyped

        attr_reader next_drip: untyped

        attr_reader limiter: untyped

        def initialize: (untyped limiter, untyped next_drip) -> void

        def method_missing: (*untyped args) -> untyped

        def respond_to_missing?: (untyped name) -> untyped
      end
    end
  end
end
module Sidekiq
  module Limiter
    class Middleware
      include Sidekiq::ServerMiddleware

      def call: (untyped inst, untyped job, untyped queue) { () -> untyped } -> untyped
    end
  end
end
module Sidekiq
  module Limiter
    #
    # Implements a points-based rate limiter.
    #
    # This is an implementation of the leaky-bucket algorithm, wherein a
    # bucket of fixed size is filled with points at a given rate. Each operation
    # is associated with a cost, and the operation is only allowed if the total cost
    # of the operation is less than or equal to the current number of points in the bucket.
    #
    # Caller must provide an estimate of the expected cost in points and then use `points_used`
    # to report the actual number of points consumed. The remote service will typically respond
    # with the points consumed, e.g. via an HTTP Response Header or within the response payload.
    #
    #   limiter.within_limit(estimate: 400) do |result|
    #     # make call
    #     actual_pts = 300
    #     result.points_used(actual_pts)
    #   end
    #
    # To be clear, `points_used` is strictly optional. Using it ensures Sidekiq doesn't prematurely
    # limit your calls if you are overestimating the cost.
    class Points < Base
      @size: untyped

      @interval: untyped

      @key: untyped

      attr_reader size: untyped

      attr_reader interval: untyped

      def initialize: (untyped name, untyped size, untyped interval, ?::Hash[untyped, untyped] options) -> void

      def key: () -> untyped

      def within_limit: (estimate: untyped) { (untyped) -> untyped } -> (untyped | nil)

      class Result
        @limiter: untyped

        @wait_time: untyped

        @estimate: untyped

        @points_left: untyped

        @actual: untyped

        attr_reader limiter: untyped

        attr_reader wait_time: untyped

        attr_reader estimate: untyped

        attr_reader points_left: untyped

        attr_reader actual: untyped

        def initialize: (untyped limiter, untyped wait_time, untyped estimate, untyped points_left) -> void

        # After making the call to the remote side which consumes the points,
        # call this method with the actual points consumed so the points tracking
        # is as accurate as possible.
        def points_used: (untyped actual_pts) -> nil

        # This is realtime data and can change at any moment based
        # on usage from other jobs/threads.
        def current_points: () -> untyped

        def method_missing: (*untyped args) -> untyped

        def respond_to_missing?: (untyped name) -> untyped

        def to_s: () -> ::String
      end
    end
  end
end
module Sidekiq
  class LimiterSet
    include Enumerable[untyped]

    def each: () { (untyped) -> untyped } -> untyped

    def paginate: (untyped cursor, untyped filter) { (?) -> untyped } -> ::Array[untyped]
  end

  module Limiter
    class Status
      @key: untyped

      @type: untyped

      @name: untyped

      @helper: untyped

      class Concurrent
        @available: untyped

        @used: untyped

        @metrics: untyped

        @size: untyped

        attr_accessor used: untyped

        attr_accessor size: untyped

        attr_accessor available: untyped

        def initialize: (untyped key, untyped name) -> void

        def rate: () -> untyped

        def type: () -> :concurrent

        def type_name: () -> "Concurrent"

        def available_pct: () -> (0 | untyped)

        def used_pct: () -> (0 | untyped)

        def held: () -> untyped

        def held_time: () -> untyped

        def immediate: () -> untyped

        def reclaimed: () -> untyped

        def waited: () -> untyped

        def wait_time: () -> untyped

        def overtime: () -> untyped
      end

      class Window
        @size: untyped

        @interval: untyped

        attr_accessor size: untyped

        attr_accessor interval: untyped

        def initialize: (untyped key, untyped name) -> void

        def rate: () -> ::String

        def type: () -> :window

        def type_name: () -> "Window"
      end

      class Bucket
        @name: untyped

        @size: untyped

        @interval: untyped

        attr_accessor size: untyped

        attr_accessor interval: untyped

        def initialize: (untyped key, untyped name) -> void

        def rate: () -> ::String

        def type: () -> :bucket

        def type_name: () -> "Bucket"

        def history: () -> untyped
      end

      class LeakyBucket
        @size: untyped

        @interval: untyped

        @drops: untyped

        @hit: untyped

        @miss: untyped

        @waited: untyped

        attr_reader size: untyped

        attr_reader interval: untyped

        attr_reader drops: untyped

        attr_reader hit: untyped

        attr_reader miss: untyped

        attr_reader waited: untyped

        def initialize: (untyped key, untyped name) -> void

        def type: () -> :leaky

        def type_name: () -> "Leaky Bucket"

        def rate: () -> ::String
      end

      class Points
        @size: untyped

        @interval: untyped

        @points: untyped

        @hit: untyped

        @miss: untyped

        @waited: untyped

        attr_reader size: untyped

        attr_reader interval: untyped

        attr_reader points: untyped

        attr_reader hit: untyped

        attr_reader miss: untyped

        attr_reader waited: untyped

        def initialize: (untyped key, untyped name) -> void

        def type: () -> :points

        def type_name: () -> "Points"

        def rate: () -> ::String
      end

      attr_accessor key: untyped

      attr_accessor name: untyped

      def initialize: (untyped key) -> void

      def helper: () -> untyped

      def method_missing: (*untyped args) -> untyped

      def respond_to_missing?: (untyped name) -> untyped
    end
  end
end
module Sidekiq
  module Limiter
    class Unlimited < Sidekiq::Limiter::Base
      NONE: ::Hash[untyped, untyped]

      def initialize: (*untyped args) -> void

      def within_limit: (*untyped args, **untyped kwargs) { (untyped) -> untyped } -> untyped

      def key: () -> untyped

      class ResultStub
        def respond_to_missing?: (*untyped) -> true

        def method_missing: (*untyped) -> nil
      end
    end
  end
end
module Sidekiq
  module Limiter
    class Window < Base
      @size: untyped

      @interval: untyped

      @bucket: untyped

      # this doesn't need to be thread-safe as this operation
      # is idempotent so the race condition is fine.
      @done: untyped

      @key: untyped

      INTERVALS: untyped

      attr_reader interval: untyped

      attr_reader size: untyped

      attr_reader bucket: untyped

      alias count size

      # Create a rate limiter of +size+ per +interval+, e.g. 5 per second.
      # +interval+ may be a symbol (:second, :minute) or an integer number
      # of seconds.
      #
      # This implements a "sliding window" limiter so you cannot perform
      # more than N operations until a full interval has passed.
      #
      # Name should be a URL-safe descriptor, i.e. "user_12345", not "Bob's Rate".
      #
      # Options:
      #   :wait_timeout - maximum time to pause while waiting for an available bucket, only applicable
      #               to :second buckets only.
      #
      def initialize: (untyped name, untyped size, untyped interval, untyped options) -> void

      def establish: () -> untyped

      def key: () -> untyped

      #
      # Yield if the current interval has not gone over quota.
      # :used is the number of points used by this call, defaulting to 1.
      #
      # If this is a :second-based limiter, will +sleep+ up to
      # +wait_timeout+ seconds until it can fit within quota or
      # raise Sidekiq::Limiter::OverLimit.
      def within_limit: (?used: ::Integer) { () -> untyped } -> (untyped | nil)
    end
  end
end
module Sidekiq
  module Periodic
    class Config
      @config: untyped

      @work: untyped

      @version: untyped

      @locked: untyped

      @tz: untyped

      include Sidekiq::Component

      # Periodic data lives for 90 days by default
      STATIC_TTL: untyped

      # The version is SHA hash of all statically defined jobs.  If
      # any job data changes, the version will change also.  In
      # this way we know when we need to resync job data to Redis
      # by checking a single key.
      attr_reader version: untyped

      attr_reader work: untyped

      #
      # Configure the subsystem to use a specific timezone for
      # all periodic jobs. This overrides the default of the system's timezone.
      # The system can be set to "Los Angeles" while this is set to "New York".
      # Must quack like Time, ActiveSupport::TimeZone or similar.
      # https://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html
      attr_writer tz: untyped

      def initialize: (untyped config) -> void

      def register: (untyped schedule, untyped klass, ?::Hash[untyped, untyped] options) -> untyped

      def empty?: () -> untyped

      def persist: () -> untyped

      def clear: () -> untyped

      def finish!: () -> untyped

      def queue_for: () -> untyped
    end
  end
end
# Parses cron expressions and computes the next occurence of the "job"
#
module Sidekiq
  class CronParser
    @source: untyped

    @time_source: untyped

    @_interpolate_weekdays_cache: untyped

    @time_specs: untyped

    # internal "mutable" time representation
    class InternalTime
      @year: untyped

      @month: untyped

      @day: untyped

      @hour: untyped

      @min: untyped

      @gmtoff: untyped

      @time_source: untyped

      attr_accessor year: untyped

      attr_accessor month: untyped

      attr_accessor day: untyped

      attr_accessor hour: untyped

      attr_accessor min: untyped

      attr_accessor time_source: untyped

      def initialize: (untyped time, ?untyped time_source) -> void

      def to_time: () -> untyped

      def inspect: () -> untyped
    end

    SYMBOLS: { "jan" => "1", "feb" => "2", "mar" => "3", "apr" => "4", "may" => "5", "jun" => "6", "jul" => "7", "aug" => "8", "sep" => "9", "oct" => "10", "nov" => "11", "dec" => "12", "sun" => "0", "mon" => "1", "tue" => "2", "wed" => "3", "thu" => "4", "fri" => "5", "sat" => "6" }

    def initialize: (untyped source, ?untyped time_source) -> void

    def interpret_vixieisms: (untyped spec) -> untyped

    # returns the next occurence after the given date
    def next: (?untyped now, ?::Integer num) -> untyped

    # returns the last occurence before the given date
    def last: (?untyped now, ?::Integer num) -> untyped

    SUBELEMENT_REGEX: ::Regexp

    def parse_element: (untyped elem, untyped allowed_range) -> ::Array[untyped]

    def recursive_calculate: (untyped meth, untyped time, untyped num) -> untyped

    # returns a list of days which do both match time_spec[:dom] or time_spec[:dow]
    def interpolate_weekdays: (untyped year, untyped month) -> untyped

    def interpolate_weekdays_without_cache: (untyped year, untyped month) -> ::Array[untyped]

    def nudge_year: (untyped t, ?::Symbol dir) -> untyped

    def nudge_month: (untyped t, ?::Symbol dir) -> untyped

    def date_valid?: (untyped t, ?::Symbol dir) -> untyped

    def nudge_date: (untyped t, ?::Symbol dir, ?bool can_nudge_month) -> untyped

    def nudge_hour: (untyped t, ?::Symbol dir) -> untyped

    def nudge_minute: (untyped t, ?::Symbol dir) -> untyped

    def time_specs: () -> untyped

    def substitute_parse_symbols: (untyped str) -> untyped

    def stepped_range: (untyped rng, ?::Integer step) -> untyped

    # returns the smallest element from allowed which is greater than current
    # returns nil if no matching value was found
    def find_best_next: (untyped current, untyped allowed, untyped dir) -> untyped

    def validate_source: () -> untyped
  end
end
module Sidekiq
  module Periodic
    #
    # We have N sidekiq processes starting up and one shared Redis.
    # We want to get a common view of the periodic jobs.  It is
    # assumed that all Sidekiqs are running the same codebase but
    # we do want to handle the case of old Sidekiqs which are
    # lingering around.
    #
    # To prevent processes from stepping on each other when updating
    # Redis, we elect a single Sidekiq process as leader to update
    # the periodic data model.
    #
    # Periodic data is versioned so that if any jobs are added, removed
    # or changed, the data model keys in Redis will change completely.  The
    # old version will quietly garbage collect when its TTL expires.
    #
    # Startup:
    # 1. register periodic jobs in-memory
    # 2. generate version SHA from periodic data
    # 3. elect leader for version
    # 4. leader pushes periodic data to Redis if version has changed
    #
    # Ongoing
    # 1. All processes run a Periodic Actor every minute:
    #   a. on the leader, this checks for new periodic jobs to create
    #   b. creates those jobs
    # 2. On all others, this checks if leader is still active.
    #
    class Manager
      @config: untyped

      @q: untyped

      @thread: untyped

      @done: untyped

      @sleeper: untyped

      @mutex: untyped

      @reloader: untyped

      @cronconfig: untyped

      include Sidekiq::Component

      SAVE_COUNT: 25

      def initialize: (untyped config) -> void

      def persist: (untyped cronconfig) -> untyped

      def start: () -> untyped

      def terminate: () -> untyped

      def cycle: () -> untyped

      def process: (?untyped now) -> untyped
    end
  end
end
module Sidekiq
  module Periodic
    #
    # A static loop is a periodic job which is registered with the
    # system upon startup, e.g. your typical cron job.
    #
    class StaticLoop
      @schedule: untyped

      @klass: untyped

      @options: untyped

      @src: untyped

      @cron: untyped

      @lid: untyped

      attr_accessor schedule: untyped

      attr_accessor options: untyped

      def initialize: (untyped schedule, untyped klass, untyped options, ?untyped time_source) -> void

      def tz_name: () -> untyped

      def next_occurrence: (?untyped now, ?untyped time_now) -> untyped

      def job_hash: () -> untyped

      attr_reader klass: untyped

      def lid: () -> untyped
    end
  end
end
# Useful for verifying the cron registration block in your initializer.
#
#     CRON_BLOCK = ->(mgr) { mgr.register("0 1 * * *", "NoSuchClass") }
#     ct = Sidekiq::Periodic::ConfigTester.new
#     ct.verify(CRON_BLOCK) # raises NameError
class Sidekiq::Periodic::ConfigTester
  @config: untyped

  @pcfg: untyped

  @constantize: untyped

  include Sidekiq::Component

  def initialize: (?constantize: bool) -> void

  # @returns Array<Sidekiq::Periodic::StaticLoop>
  def verify: () { (?) -> untyped } -> untyped
end
